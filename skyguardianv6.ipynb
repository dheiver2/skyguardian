{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8377042,"sourceType":"datasetVersion","datasetId":4974923},{"sourceId":8380181,"sourceType":"datasetVersion","datasetId":4983338},{"sourceId":138401128,"sourceType":"kernelVersion"},{"sourceId":46340,"sourceType":"modelInstanceVersion","modelInstanceId":38840},{"sourceId":45698,"sourceType":"modelInstanceVersion","modelInstanceId":38313}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport urllib\nfrom super_gradients.common.object_names import Models\nfrom super_gradients.training import models\n\nclass ObjectDetector:\n    def __init__(self, model):\n        self.model = model\n\n    def process_frame(self, frame, confidence_threshold, filter_label):\n        predictions = self.model.predict(frame, conf=confidence_threshold)\n        frame_predictions = []\n\n        if not isinstance(predictions, list):\n            predictions = [predictions]\n\n        for prediction in predictions:\n            class_names = prediction.class_names\n            labels = prediction.prediction.labels\n            confidence = prediction.prediction.confidence\n            bboxes = prediction.prediction.bboxes_xyxy\n\n            for label, conf, bbox in zip(labels, confidence, bboxes):\n                if class_names[int(label)] == filter_label and conf >= confidence_threshold:\n                    frame_predictions.append({\n                        \"class_name\": class_names[int(label)],\n                        \"confidence\": conf,\n                        \"bbox\": bbox\n                    })\n\n                    xmin, ymin, xmax, ymax = map(int, bbox)\n                    cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n                    cv2.putText(frame, f'{filter_label.capitalize()}: {conf:.2f}', (xmin, ymin - 10),\n                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n        return frame, frame_predictions\n\n\n    def detect_objects(self, input_source, output_path=None, max_frames=None, confidence_threshold=0.2, filter_label=None):\n        if isinstance(input_source, str):\n            if input_source.startswith('http'):\n                stream = urllib.request.urlopen(input_source)\n                bytes = bytearray()\n                frame = None  # Inicializa a variável frame com None\n                while True:\n                    bytes += stream.read(1024)\n                    a = bytes.find(b'\\xff\\xd8')\n                    b = bytes.find(b'\\xff\\xd9')\n                    if a != -1 and b != -1:\n                        jpg = bytes[a:b + 2]\n                        bytes = bytes[b + 2:]\n                        frame = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n                        break\n                frame_height, frame_width, _ = frame.shape  # Inicializa as variáveis frame_width e frame_height\n            else:\n                cap = cv2.VideoCapture(input_source)\n                frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n                frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        else:\n            cap = cv2.VideoCapture(input_source)\n            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n        if output_path is not None:\n            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n            out = cv2.VideoWriter(output_path, fourcc, 20.0, (frame_width, frame_height))\n            output_is_image = False\n        else:\n            output_is_image = True\n\n        frame_count = 0\n        while True:\n            if isinstance(input_source, str) and input_source.startswith('http'):\n                bytes += stream.read(1024)\n                a = bytes.find(b'\\xff\\xd8')\n                b = bytes.find(b'\\xff\\xd9')\n                if a != -1 and b != -1:\n                    jpg = bytes[a:b + 2]\n                    bytes = bytes[b + 2:]\n                    frame = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n\n                    frame_processed, _ = self.process_frame(frame, confidence_threshold, filter_label)\n                    out.write(frame_processed)\n\n                    if cv2.waitKey(1) & 0xFF == ord('q'):\n                        break\n            else:\n                ret, frame = cap.read()\n                if not ret:\n                    break\n\n                frame_processed, _ = self.process_frame(frame, confidence_threshold, filter_label)\n\n                if output_is_image:\n                    cv2.imshow('Live Object Detection', frame_processed)\n                    if cv2.waitKey(1) & 0xFF == ord('q'):\n                        break\n                else:\n                    out.write(frame_processed)\n                    frame_count += 1\n                    if max_frames is not None and frame_count >= max_frames:\n                        break\n\n        if not output_is_image:\n            cap.release()\n            out.release()\n            print(\"Vídeo com previsões salvo com sucesso em:\", output_path)\n        else:\n            cv2.destroyAllWindows()\n\n\n# Carregue o modelo YOLO-NAS-L\nmodel = models.get(Models.YOLO_NAS_L, pretrained_weights=\"coco\")\n\n# Instancie o ObjectDetector com o modelo carregado\ndetector = ObjectDetector(model)\n\n# Fonte de entrada (pode ser um número de dispositivo de webcam ou o nome de um arquivo de vídeo)\n# input_source = 0  # 0 para webcam, ou o caminho para um arquivo de vídeo\ninput_source =  '/kaggle/input/video/videoplayback (2).mp4'\n\n# Caminho de saída (opcional, deixe como None para visualização em tempo real)\noutput_path = \"/kaggle/working/saida_com_previsoes.mp4\"  # ou None para visualização em tempo real\n\n# Número máximo de quadros a serem processados (opcional)\nmax_frames = 1000  # Processará apenas os primeiros 1000 quadros\n\n# Limiar de confiança para detecção de objetos (opcional)\nconfidence_threshold = 0.2\n\n# Label do objeto que deseja filtrar (opcional)\nfilter_label = 'person'\n\n# Chame o método detect_objects para processar a entrada e salvar o vídeo de saída (se aplicável)\ndetector.detect_objects(input_source, output_path, max_frames=max_frames, confidence_threshold=confidence_threshold, filter_label=filter_label)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-11T15:19:49.018557Z","iopub.execute_input":"2024-05-11T15:19:49.019465Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"[2024-05-11 15:19:49] WARNING - checkpoint_utils.py - :warning: The pre-trained models provided by SuperGradients may have their own licenses or terms and conditions derived from the dataset used for pre-training.\n It is your responsibility to determine whether you have permission to use the models for your use case.\n The model you have requested was pre-trained on the coco dataset, published under the following terms: https://cocodataset.org/#termsofuse\n[2024-05-11 15:19:49] INFO - checkpoint_utils.py - License Notification: YOLO-NAS pre-trained weights are subjected to the specific license terms and conditions detailed in \nhttps://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS.md\nBy downloading the pre-trained weight files you agree to comply with these terms.\n[2024-05-11 15:19:50] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_l\n[2024-05-11 15:19:50] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:19:51] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:19:52] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:19:53] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:19:54] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:19:55] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:19:56] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:19:57] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:19:58] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:19:59] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:00] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:01] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:02] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:03] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:04] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:05] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:06] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:07] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:08] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:09] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:10] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:11] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:12] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:13] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:14] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:15] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n[2024-05-11 15:20:17] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n","output_type":"stream"}]}]}